{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zF9D5Fn2OSQW",
        "pPRqWB_Sbn8Q",
        "w-WCKvh-bPDH",
        "1Nuho1BTbdmf",
        "Uxl5sULeb-lO",
        "4Lqxbiargux7",
        "fZj6tvo1jSMm",
        "oWsHTIn-mpLM",
        "5mlB9DKVn8YP",
        "LKz3yaLitD6k",
        "NtD32wzMsaNW",
        "I-yzUrQasG7b",
        "X3oja5RG9Ky5"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIua+QxcFTla2gQq4xdhYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Untick/IrisID_gr2/blob/Alexey-Tatarinov-folder/Alexey%20Tatarinov/Iris_Autokeras_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Импорт библиотек и модулей**"
      ],
      "metadata": {
        "id": "zF9D5Fn2OSQW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YzRcKkv4LE6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d465690c-e016-4d2c-81c8-b5a69265c0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autokeras\n",
            "  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autokeras) (23.1)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from autokeras) (2.12.0)\n",
            "Collecting keras-tuner>=1.1.0 (from autokeras)\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-nlp>=0.4.0 (from autokeras)\n",
            "  Downloading keras_nlp-0.5.2-py3-none-any.whl (527 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from autokeras) (1.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.22.4)\n",
            "Collecting tensorflow-text (from keras-nlp>=0.4.0->autokeras)\n",
            "  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.27.1)\n",
            "Collecting kt-legacy (from keras-tuner>=1.1.0->autokeras)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.32.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autokeras) (2022.7.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.8.0->autokeras) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.8.0->autokeras) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (2.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp>=0.4.0->autokeras) (0.13.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (3.2.2)\n",
            "Successfully installed autokeras-1.1.0 keras-nlp-0.5.2 keras-tuner-1.3.5 kt-legacy-1.0.5 tensorflow-text-2.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Augmentor\n",
            "  Downloading Augmentor-0.2.12-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (8.4.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (1.22.4)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.12\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "import os\n",
        "\n",
        "! pip install autokeras\n",
        "import autokeras as ak\n",
        "\n",
        "! pip install Augmentor\n",
        "import Augmentor\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "from tensorflow.keras.layers import (Dense, Conv2D, MaxPooling2D, Flatten, \n",
        "                                     Dropout, BatchNormalization, Rescaling,\n",
        "                                     GlobalAveragePooling2D, RandomFlip, Input,\n",
        "                                     RandomRotation, RandomZoom, RandomContrast)\n",
        "\n",
        "from tensorflow.keras.applications import VGG19, ResNet50, Xception\n",
        "\n",
        "# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import (ImageDataGenerator, \n",
        "                                                 DirectoryIterator)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from PIL import Image, ImageEnhance\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Подготовка датасета**"
      ],
      "metadata": {
        "id": "pPRqWB_Sbn8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задание гиперпараметров**"
      ],
      "metadata": {
        "id": "w-WCKvh-bPDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH          = '/content/drive/MyDrive/iris_ds'\n",
        "TRAIN_PATH_AUG      = '/content/drive/MyDrive/Iris'\n",
        "\n",
        "VAL_SPLIT           = 0.2\n",
        "\n",
        "IMG_WIDTH_1         = 160\n",
        "IMG_HEIGHT_1        = 120\n",
        "IMG_WIDTH_2         = 80\n",
        "IMG_HEIGHT_2        = 60\n",
        "IMG_CHANNELS        = 3\n",
        "\n",
        "ROTATION_RANGE      = 10\n",
        "WIDTH_SHIFT_RANGE   = 0.1\n",
        "HEIGHT_SHIFT_RANGE  = 0.1\n",
        "ZOOM_RANGE          = 0.1\n",
        "BRIGHTNESS_RANGE    = (0.5, 1.3)\n",
        "HORIZONTAL_FLIP     = False\n",
        "\n",
        "EPOCHS              = 20\n",
        "BATCH_SIZE          = 24\n",
        "OPTIMIZER_LEGACY    = tf.keras.optimizers.legacy.Adam(0.0001)\n",
        "OPTIMIZER           = tf.keras.optimizers.Adam(0.0001)"
      ],
      "metadata": {
        "id": "gSCENm0FbPQa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Загрузка датасета**"
      ],
      "metadata": {
        "id": "1Nuho1BTbdmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PZYmJsQbbdzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e5dade-5cc6-41a5-e7a7-11ff6c6f5ed7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Аугментация**"
      ],
      "metadata": {
        "id": "Uxl5sULeb-lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(TRAIN_PATH):\n",
        "    if os.path.isdir(os.path.join(TRAIN_PATH, folder)):\n",
        "        # Создаем генератор аугментации для каждой папки\n",
        "        p = Augmentor.Pipeline(os.path.join(TRAIN_PATH, folder), output_directory=os.path.join(f'/content/drive/MyDrive/Iris/{folder}'))\n",
        "        # Добавляем операции аугментации\n",
        "        # Вращение изображения\n",
        "        p.rotate(probability=0.2, max_left_rotation=10, max_right_rotation=10)\n",
        "        # увеличение\n",
        "        #p.zoom(probability=0.2, min_factor=1.1, max_factor=1.2)\n",
        "        # Обрезание изображения\n",
        "        p.crop_random(probability=0.1, percentage_area=0.9)\n",
        "        # Изменение яркости\n",
        "        p.random_brightness(probability=0.5, min_factor=0.5, max_factor=1.3)\n",
        "        # Изменение контрасности\n",
        "        p.random_contrast(probability=0.5, min_factor=0.5, max_factor=1.3)\n",
        "        # Применяем аугментацию\n",
        "        p.sample(50)\n",
        "print('Аугментация завершена')"
      ],
      "metadata": {
        "id": "G08WRtGbb-1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Создание базы**"
      ],
      "metadata": {
        "id": "4Lqxbiargux7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_LIST = sorted(os.listdir(TRAIN_PATH_AUG))\n",
        "CLASS_COUNT = len(CLASS_LIST)\n",
        "\n",
        "print(f'Количество классов: {CLASS_COUNT}, метки классов: {CLASS_LIST}')"
      ],
      "metadata": {
        "id": "fhf5nbG5gvcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4e8154-eae5-423e-daf3-8d48d216efda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество классов: 64, метки классов: ['client_1', 'client_10', 'client_11', 'client_12', 'client_13', 'client_14', 'client_15', 'client_16', 'client_17', 'client_18', 'client_19', 'client_2', 'client_20', 'client_21', 'client_22', 'client_23', 'client_24', 'client_25', 'client_26', 'client_27', 'client_28', 'client_29', 'client_3', 'client_30', 'client_31', 'client_32', 'client_33', 'client_34', 'client_35', 'client_36', 'client_37', 'client_38', 'client_39', 'client_4', 'client_40', 'client_41', 'client_42', 'client_43', 'client_44', 'client_45', 'client_46', 'client_47', 'client_48', 'client_49', 'client_5', 'client_50', 'client_51', 'client_52', 'client_53', 'client_54', 'client_55', 'client_56', 'client_57', 'client_58', 'client_59', 'client_6', 'client_60', 'client_61', 'client_62', 'client_63', 'client_64', 'client_7', 'client_8', 'client_9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_files = []\n",
        "data_labels = []\n",
        "\n",
        "for class_label in range(CLASS_COUNT):    # Для всех классов по порядку номеров (их меток)\n",
        "    class_name = CLASS_LIST[class_label]  # Выборка имени класса из списка имен\n",
        "    class_path = f'{TRAIN_PATH_AUG}/{class_name}'  # Формирование полного пути к папке с изображениями класса\n",
        "    class_files = os.listdir(class_path)  # Получение списка имен файлов с изображениями текущего класса\n",
        "    data_files += [f'{class_path}/{file_name}' for file_name in class_files]\n",
        "    data_labels += [class_label] * len(class_files)\n",
        "    print(f'Размер класса {class_name} составляет {len(class_files)} снимков')\n",
        "\n",
        "print('Общий размер базы для обучения:', len(data_labels))"
      ],
      "metadata": {
        "id": "z33I7y47hFnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a2f765-826a-48a4-be27-e46610142b8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер класса client_1 составляет 50 снимков\n",
            "Размер класса client_10 составляет 50 снимков\n",
            "Размер класса client_11 составляет 50 снимков\n",
            "Размер класса client_12 составляет 50 снимков\n",
            "Размер класса client_13 составляет 50 снимков\n",
            "Размер класса client_14 составляет 50 снимков\n",
            "Размер класса client_15 составляет 50 снимков\n",
            "Размер класса client_16 составляет 50 снимков\n",
            "Размер класса client_17 составляет 50 снимков\n",
            "Размер класса client_18 составляет 50 снимков\n",
            "Размер класса client_19 составляет 50 снимков\n",
            "Размер класса client_2 составляет 50 снимков\n",
            "Размер класса client_20 составляет 50 снимков\n",
            "Размер класса client_21 составляет 50 снимков\n",
            "Размер класса client_22 составляет 50 снимков\n",
            "Размер класса client_23 составляет 50 снимков\n",
            "Размер класса client_24 составляет 50 снимков\n",
            "Размер класса client_25 составляет 50 снимков\n",
            "Размер класса client_26 составляет 50 снимков\n",
            "Размер класса client_27 составляет 50 снимков\n",
            "Размер класса client_28 составляет 50 снимков\n",
            "Размер класса client_29 составляет 50 снимков\n",
            "Размер класса client_3 составляет 50 снимков\n",
            "Размер класса client_30 составляет 50 снимков\n",
            "Размер класса client_31 составляет 50 снимков\n",
            "Размер класса client_32 составляет 50 снимков\n",
            "Размер класса client_33 составляет 50 снимков\n",
            "Размер класса client_34 составляет 50 снимков\n",
            "Размер класса client_35 составляет 50 снимков\n",
            "Размер класса client_36 составляет 50 снимков\n",
            "Размер класса client_37 составляет 50 снимков\n",
            "Размер класса client_38 составляет 50 снимков\n",
            "Размер класса client_39 составляет 50 снимков\n",
            "Размер класса client_4 составляет 50 снимков\n",
            "Размер класса client_40 составляет 50 снимков\n",
            "Размер класса client_41 составляет 50 снимков\n",
            "Размер класса client_42 составляет 50 снимков\n",
            "Размер класса client_43 составляет 50 снимков\n",
            "Размер класса client_44 составляет 50 снимков\n",
            "Размер класса client_45 составляет 50 снимков\n",
            "Размер класса client_46 составляет 50 снимков\n",
            "Размер класса client_47 составляет 50 снимков\n",
            "Размер класса client_48 составляет 50 снимков\n",
            "Размер класса client_49 составляет 50 снимков\n",
            "Размер класса client_5 составляет 50 снимков\n",
            "Размер класса client_50 составляет 50 снимков\n",
            "Размер класса client_51 составляет 50 снимков\n",
            "Размер класса client_52 составляет 50 снимков\n",
            "Размер класса client_53 составляет 50 снимков\n",
            "Размер класса client_54 составляет 50 снимков\n",
            "Размер класса client_55 составляет 50 снимков\n",
            "Размер класса client_56 составляет 50 снимков\n",
            "Размер класса client_57 составляет 50 снимков\n",
            "Размер класса client_58 составляет 50 снимков\n",
            "Размер класса client_59 составляет 50 снимков\n",
            "Размер класса client_6 составляет 50 снимков\n",
            "Размер класса client_60 составляет 50 снимков\n",
            "Размер класса client_61 составляет 50 снимков\n",
            "Размер класса client_62 составляет 50 снимков\n",
            "Размер класса client_63 составляет 50 снимков\n",
            "Размер класса client_64 составляет 50 снимков\n",
            "Размер класса client_7 составляет 50 снимков\n",
            "Размер класса client_8 составляет 50 снимков\n",
            "Размер класса client_9 составляет 50 снимков\n",
            "Общий размер базы для обучения: 3200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_images_1 = []\n",
        "\n",
        "# for file_name in data_files:\n",
        "#     img = Image.open(file_name).resize((IMG_WIDTH_1, IMG_HEIGHT_1)) \n",
        "#     img_np = np.array(img)\n",
        "#     data_images_1.append(img_np)\n",
        "\n",
        "# x_data_big = np.array(data_images_1)\n",
        "# y_data = np.array(data_labels)\n",
        "\n",
        "# print(f'В массив собрано {len(data_images_1)} фотографий следующей формы: {img_np.shape}')\n",
        "# print(f'Общий массив данных изображений следующей формы: {x_data_big.shape}')\n",
        "# print(f'Общий массив меток классов следующей формы: {y_data.shape}')\n",
        "\n",
        "data_images = []\n",
        "\n",
        "for file_name in data_files:\n",
        "    img = Image.open(file_name).resize((IMG_WIDTH_2, IMG_HEIGHT_2)) \n",
        "    img_np = np.array(img)\n",
        "    data_images.append(img_np)\n",
        "\n",
        "x_data_small = np.array(data_images)\n",
        "y_data = np.array(data_labels)\n",
        "\n",
        "print(f'В массив собрано {len(data_images)} фотографий следующей формы: {img_np.shape}')\n",
        "print(f'Общий массив данных изображений следующей формы: {x_data_small.shape}')\n",
        "print(f'Общий массив меток классов следующей формы: {y_data.shape}')"
      ],
      "metadata": {
        "id": "Ur6hUXa4hFwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc79d85e-2c7c-4a59-dae4-4bc661325537"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В массив собрано 3200 фотографий следующей формы: (60, 80, 3)\n",
            "Общий массив данных изображений следующей формы: (3200, 60, 80, 3)\n",
            "Общий массив меток классов следующей формы: (3200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Деление на выборки**"
      ],
      "metadata": {
        "id": "fZj6tvo1jSMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение выборки на обучающую, проверочную и тестовую\n",
        "# x_ds_big, x_val_big, y_ds_big, y_val_big = train_test_split(x_data_big, y_data, test_size=0.2, random_state=42)\n",
        "# x_train_big, x_test_big, y_train_big, y_test_big = train_test_split(x_ds_big, y_ds_big, test_size=0.1, random_state=42)\n",
        "\n",
        "x_ds_small, x_val_small, y_ds_small, y_val_small = train_test_split(x_data_small, y_data, test_size=0.2, random_state=42)\n",
        "x_train_small, x_test_small, y_train_small, y_test_small = train_test_split(x_ds_small, y_ds_small, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "wxfvjao-hGYG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_small = to_categorical(y_train_small)\n",
        "# y_train_big = to_categorical(y_train_big)\n",
        "\n",
        "y_val_small = to_categorical(y_val_small)\n",
        "# y_val_big = to_categorical(y_val_big)\n",
        "\n",
        "y_test_small = to_categorical(y_test_small)\n",
        "# y_test_big = to_categorical(y_test_big)"
      ],
      "metadata": {
        "id": "Jyj_6lNThGbs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Размерности датасетов с изображениями 160 на 120')\n",
        "# print('Тренировочный датасет:')\n",
        "# print(x_train_big.shape)\n",
        "# print(y_train_big.shape)\n",
        "# print('Проверочный датасет:')\n",
        "# print(x_val_big.shape)\n",
        "# print(y_val_big.shape)\n",
        "# print('Тестовый датасет:')\n",
        "# print(x_test_big.shape)\n",
        "# print(y_test_big.shape)\n",
        "\n",
        "print('\\nРазмерности датасетов с изображениями 80 на 60')\n",
        "print('Тренировочный датасет:')\n",
        "print(x_train_small.shape)\n",
        "print(y_train_small.shape)\n",
        "print('Проверочный датасет:')\n",
        "print(x_val_small.shape)\n",
        "print(y_val_small.shape)\n",
        "print('Тестовый датасет:')\n",
        "print(x_test_small.shape)\n",
        "print(y_test_small.shape)"
      ],
      "metadata": {
        "id": "CGxSwIAdhGfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577cc2f8-005e-4f6f-e37d-9e1e03e3cb3e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Размерности датасетов с изображениями 80 на 60\n",
            "Тренировочный датасет:\n",
            "(2304, 60, 80, 3)\n",
            "(2304, 64)\n",
            "Проверочный датасет:\n",
            "(640, 60, 80, 3)\n",
            "(640, 64)\n",
            "Тестовый датасет:\n",
            "(256, 60, 80, 3)\n",
            "(256, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Оптимизация обучения модели**"
      ],
      "metadata": {
        "id": "oWsHTIn-mpLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "# validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "MOmL13JHllMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath=\"my_model.hdf5\", monitor=\"val_loss\", verbose=0, save_best_only=True)"
      ],
      "metadata": {
        "id": "ENwl_m9gllQQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Работа с моделью**"
      ],
      "metadata": {
        "id": "5mlB9DKVn8YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = ak.ImageClassifier(\n",
        "    max_trials=2,\n",
        "    objective='val_accuracy',\n",
        "    directory='automl_irisID_1',\n",
        "    overwrite=True)\n",
        "\n",
        "clf.fit(x_train_small, y_train_small, epochs=10, validation_data=(x_val_small, y_val_small))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyuf4PROXWOO",
        "outputId": "d5bb2049-1f2c-46ef-e5ad-8b0d7e1a16e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 06m 06s]\n",
            "val_accuracy: 0.5234375\n",
            "\n",
            "Best val_accuracy So Far: 0.981249988079071\n",
            "Total elapsed time: 00h 06m 31s\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 2s 17ms/step - loss: 2.7656 - accuracy: 0.3411 - val_loss: 0.9485 - val_accuracy: 0.7531\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.4621 - accuracy: 0.8720 - val_loss: 0.2634 - val_accuracy: 0.9281\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1449 - accuracy: 0.9596 - val_loss: 0.1397 - val_accuracy: 0.9641\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.0420 - accuracy: 0.9909 - val_loss: 0.1379 - val_accuracy: 0.9594\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0313 - accuracy: 0.9922 - val_loss: 0.1053 - val_accuracy: 0.9703\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 0.1617 - val_accuracy: 0.9578\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 0.0808 - val_accuracy: 0.9719\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.0987 - val_accuracy: 0.9719\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0524 - accuracy: 0.9900 - val_loss: 0.0892 - val_accuracy: 0.9750\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.0827 - val_accuracy: 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1932076dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clf.save('model_autokeras_iris_v1', save_format=\"h5\")\n",
        "best_model = clf.export_model()\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDFr9fb5YzpU",
        "outputId": "70f2c43b-19f9-4609-9064-140bec3d61c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 60, 80, 3)]       0         \n",
            "                                                                 \n",
            " cast_to_float32 (CastToFloa  (None, 60, 80, 3)        0         \n",
            " t32)                                                            \n",
            "                                                                 \n",
            " normalization (Normalizatio  (None, 60, 80, 3)        7         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 58, 78, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 56, 76, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 28, 38, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 28, 38, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 68096)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 68096)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4358208   \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 64)               0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,377,607\n",
            "Trainable params: 4,377,600\n",
            "Non-trainable params: 7\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Проверка модели**"
      ],
      "metadata": {
        "id": "7BTf7x3BrTyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Визуализация результатов работы модели**"
      ],
      "metadata": {
        "id": "LKz3yaLitD6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация точности на обучающей выборке\n",
        "plt.plot(clf.history['accuracy'], \n",
        "         label='Доля верных ответов на обучающем наборе')\n",
        "\n",
        "# Визуализация точности на проверочной выборке\n",
        "plt.plot(clf.history['val_accuracy'], \n",
        "         label='Доля верных ответов на проверочном наборе')\n",
        "\n",
        "# Отрисовка подписей осей\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "\n",
        "# Отрисовка легенды\n",
        "plt.legend()\n",
        "\n",
        "# Вывод графика\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ePT8wjOvtEbl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "872136df-7231-40f7-a65f-94ed6377f82f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dc72e2b84ad3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Визуализация точности на обучающей выборке\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m plt.plot(best_model.history['accuracy'], \n\u001b[0m\u001b[1;32m      3\u001b[0m          label='Доля верных ответов на обучающем наборе')\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Визуализация точности на проверочной выборке\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация точности на обучающей выборке\n",
        "plt.plot(history_small.history['loss'], \n",
        "         label='Ошибка на обучающем наборе')\n",
        "\n",
        "# Визуализация точности на проверочной выборке\n",
        "plt.plot(history_small.history['val_loss'], \n",
        "         label='Ошибка на проверочном наборе')\n",
        "\n",
        "# Отрисовка подписей осей\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Ошибка')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FQlJqb0RuNcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Проверка evaluate**"
      ],
      "metadata": {
        "id": "NtD32wzMsaNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = clf.export_model()\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "X8-jHLq8oeMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533819a9-fd5f-4791-86de-24d8e0e04af2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9883\n",
            "Процент верных ответов на тестовых данных размером 80 на 60: 98.83 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_small = best_model.evaluate(x_test_small, \n",
        "                                   y_test_small, \n",
        "                                   verbose=1\n",
        "                                   )\n",
        "\n",
        "print('Процент верных ответов на тестовых данных размером 80 на 60:', round(scores_small[1],4) * 100, '%')"
      ],
      "metadata": {
        "id": "DPpduLLRDhDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Проверка predict**"
      ],
      "metadata": {
        "id": "I-yzUrQasG7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_test_small[10]\n",
        "print(x.shape)\n",
        "\n",
        "x = np.expand_dims(x, axis=0)\n",
        "print(x.shape)\n",
        "\n",
        "prediction = clf.predict(x) \n",
        "print(prediction)\n",
        "\n",
        "pred = np.argmax(prediction)\n",
        "print(f'Распознана цифра: {pred}')\n",
        "print(f'Исходная цифра: {np.argmax(y_test_small[10])}')"
      ],
      "metadata": {
        "id": "kZxForYOllYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94e1ed9-1407-4705-dcdc-283a20d088ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 80, 3)\n",
            "(1, 60, 80, 3)\n",
            "1/1 [==============================] - 0s 160ms/step\n",
            "1/1 [==============================] - 0s 7ms/step\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Распознана цифра: 5\n",
            "Исходная цифра: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Изменение версии tensorflow**"
      ],
      "metadata": {
        "id": "X3oja5RG9Ky5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orba5lB3rrbT",
        "outputId": "95ca6a3a-7034-45ac-8148-696dfde55456"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.12.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, jax, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine-rl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow==<2.9.1>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPFpIT42r-91",
        "outputId": "7f2770bc-0573-4e6e-8833-5b554b416fda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `pip install --upgrade tensorflow==<2.9.1>'\n"
          ]
        }
      ]
    }
  ]
}